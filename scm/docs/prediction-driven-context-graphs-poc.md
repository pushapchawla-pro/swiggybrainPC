# POC: Prediction-Driven Context Graphs for SKU Availability

---

## Executive Summary

**Objective**: Build a self-improving SKU availability prediction system that learns what context matters through prediction pressure, not manual curation.

**Approach**: Daily predictâ†’evaluateâ†’reflect cycle where ground truth (actual OOS) validates predictions, and errors drive context graph evolution.

**Scope**: Bangalore, FMCG Bradman Tier A (~1.2K SKUs), Top WH by volume, T+1 predictions.

**Timeline**: 13 working days across 3 weeks (Jan 12-30). Week 1: Build (Jan 12-16). Week 2: Simulation (Jan 19-23). Week 3: Live + Demo (Jan 27-30). *Excludes weekends and holidays (Jan 15: Pongal, Jan 26: Republic Day).*

**Success**: **Primary**: Positive F1 slope (self-improvement). **Secondary**: F1 >0.70 (simulation), F1 >0.75 (live), 10+ validated patterns.

**Conceptual Foundation**: [Prediction-Driven Context Graphs](./prediction-driven-context-graphs.md)

---

## 1. Problem Statement

### Current State: Diagnostic Analytics

Current AI analytics systems at Swiggy operate in **diagnostic mode**â€”asking "why did this SKU go OOS?" after the fact. This approach has fundamental limitations:

| Problem | Impact |
|---------|--------|
| **Subjective feedback** | Humans upvote/downvote, no ground truth |
| **Manual context curation** | Humans must add wikis, metadata, tags |
| **No self-improvement** | System learns from limited human feedback only |
| **Post-hoc alerting** | Issues detected after damage done |
| **7 RCA branches are incomplete** | Rules capture known patterns, miss emergent ones |

### The Core Insight

Prediction pressure forces discovery of what context mattersâ€”the context graph writes itself. (See [concept doc](./prediction-driven-context-graphs.md#why) for the theoretical foundation.)

### Why SKU Availability is the Ideal Testbed

| Property | Value for Learning |
|----------|-------------------|
| Binary outcomes | In-stock/OOS = unambiguous ground truth |
| 24hr feedback loops | Fast validation cycles |
| Bounded complexity | 7 RCA branches = manageable scope |
| Existing infrastructure | Data already available in Snowflake |
| Business impact | Direct tie to conversion metrics |

---

## 2. High-Level Approach

### Shift: Diagnostic â†’ Predictive

Instead of asking "**why did this go OOS?**" (post-hoc, subjective), ask "**will this go OOS tomorrow?**" (predictive, verifiable).

```
DIAGNOSTIC (Current)                    PREDICTIVE (POC)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"Why did X go OOS?"                     "Will X go OOS tomorrow?"
     â”‚                                        â”‚
     â–¼                                        â–¼
Human reviews RCA                        Binary outcome in 24hrs
     â”‚                                        â”‚
     â–¼                                        â–¼
Subjective feedback                      Ground truth validation
     â”‚                                        â”‚
     â–¼                                        â–¼
Limited learning                         Context graph self-curates
```

### Inner Loop: Daily Prediction Cycle

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                         â”‚
                    â–¼                                         â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
             â”‚  EVALUATE  â”‚ â—„â”€â”€â”€ Compare predictions vs       â”‚
             â”‚            â”‚      actual OOS (ground truth)    â”‚
             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
                   â”‚                                          â”‚
                   â”‚ errors                                   â”‚
                   â–¼                                          â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
             â”‚  REFLECT   â”‚ â—„â”€â”€â”€ Analyze errors, extract      â”‚
             â”‚            â”‚      patterns, update context     â”‚
             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
                   â”‚                                          â”‚
                   â”‚ patterns                                 â”‚
                   â–¼                                          â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
             â”‚  PREDICT   â”‚ â—„â”€â”€â”€ Forecast tomorrow's OOS      â”‚
             â”‚            â”‚      with reasoning               â”‚
             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
                   â”‚                                          â”‚
                   â”‚ predictions                              â”‚
                   â”‚                                          â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 24 hours â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Daily Sequence:**
```
MORNING (T+0):
  0. GIT PULL    â”€â”€â”€ Checkout latest from main branch
  1. EVALUATE    â”€â”€â”€ Compare yesterday's predictions vs actuals (binary truth)
  2. REFLECT     â”€â”€â”€ Analyze errors â†’ extract patterns â†’ update context graph
  3. PREDICT     â”€â”€â”€ Forecast OOS for tomorrow with reasoning
  4. GIT COMMIT  â”€â”€â”€ Commit all changes (predictions, evaluations, patterns) to main
```

**Why Git?** Context graph evolution is version-controlled. Every pattern, prediction, and learning is traceable. Enables rollback if patterns degrade.

### Outer Loop: Skill Evolution

The inner loop updates the context graph daily. A separate **outer loop** updates skills themselves (better processes, queries, algorithms). Triggered weekly or on error accumulation. See [Section 3.5](#35-learning-loops) for details.

### Cold-Start via Historical Simulation

Build initial context graph BEFORE going live, so Day 1 isn't starting from scratch.

```
Historical Simulation (Dec 19 - Jan 18):
  Day 1: Predict Dec 20 using ONLY Dec 19 EOD data â†’ Context graph: EMPTY
  Day 2: Evaluate â†’ Reflect (Pattern_001) â†’ Predict Dec 21
  ...
  Day 30: Context graph has 30 days of patterns â†’ READY FOR LIVE

Live (Jan 19+):
  Start with warm context graph, continue learning
```

**Anti-Cheat**: Point-in-time query filtering required. See [Section 4.4](#44-anti-cheat-requirements).

---

## 3. Low-Level Design

### 3.1 Prediction Target

**Core Question**: "Will this SKU be out of stock at this Warehouse tomorrow?"

#### 3.1.1 What We Predict

| Dimension | Value | Rationale |
|-----------|-------|-----------|
| **Prediction unit** | SKU Ã— WH | WH-led issues are 3Ã— more common (12.8% vs 4.7% POD-led). Denser signal, faster learning. |
| **Time horizon** | T+1 (tomorrow) | 24hr feedback loop for fast learning |
| **Outcome** | Binary (OOS / IN_STOCK) | Unambiguous ground truth |

> **Note**: Phase 1 focuses on WHÃ—SKU predictions (single top Bangalore WH). Phase 2 can expand to PODÃ—SKU if needed.

#### 3.1.2 Ground Truth & Evaluation

**OOS Definition** â€” For WHÃ—SKU, we **aggregate POD-level availability** across all PODs served by the warehouse:

```
For each SKUÃ—WH:
  1. Get POD-level availability % for all PODs served by WH
  2. Aggregate: WH_Availability % = weighted average across PODs (by impressions or equal weight)

OOS = TRUE  if  WH_Availability % < X%  for the day
OOS = FALSE otherwise
```

**Threshold (X): TBD** â€” To be determined via data analysis during Week 1. Considerations:
- Too high (e.g., 70%): Many false positives, noisy learning signal
- Too low (e.g., 30%): Misses partial-day stockouts that still hurt conversion
- Will analyze distribution of WH-aggregated availability % to find natural breakpoint

**Why aggregate by WH?** WH-led issues (supplier, procurement, warehouse ops) are 3Ã— more common than POD-led issues. Aggregating provides denser signal for pattern learning.

**F1 Score Calculation** â€” We use **Micro-F1**, pooling all SKUÃ—WH predictions for the day:

```
Precision = TP / (TP + FP)    â†’ "When we predict OOS, how often correct?"
Recall    = TP / (TP + FN)    â†’ "Of actual stockouts, how many caught?"
F1        = 2 Ã— (P Ã— R) / (P + R)
```

| Outcome | Meaning |
|---------|---------|
| TP | Predicted OOS, was OOS |
| FP | Predicted OOS, was IN_STOCK (false alarm) |
| FN | Predicted IN_STOCK, was OOS (missed) |

**Why F1 over Accuracy?** Class imbalance â€” most SKUs are in-stock. A naive "always predict IN_STOCK" model gets ~95% accuracy but catches zero stockouts. F1 forces us to actually predict OOS correctly.

**Secondary metrics** (for diagnostics, not exit criteria):
- OOS rate: % of SKUÃ—WH pairs that went OOS (class balance)
- Per-category F1: Performance by Dairy, Beverages, etc.
- Per-supplier F1: Are some suppliers harder to predict?

### 3.2 Architecture

**Claude Code IS the Orchestrator** with full autonomy:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLAUDE CODE (Orchestrator)                             â”‚
â”‚                                                                                â”‚
â”‚  Full autonomy: Run any query, computation, search, or model needed           â”‚
â”‚                                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    SKILLS (Procedural Knowledge)                          â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   .claude/skills/evaluate/    .claude/skills/reflect/                     â”‚ â”‚
â”‚  â”‚   .claude/skills/predict/     .claude/skills/context-graph-management/    â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   Updated via OUTER LOOP (periodic) - See Section 3.5                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    CONTEXT GRAPH (Semantic Knowledge)                     â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   brain/context-graph/patterns/by-{dimension}/   # Discovered patterns    â”‚ â”‚
â”‚  â”‚   brain/context-graph/signals.md                 # Signal importance      â”‚ â”‚
â”‚  â”‚   brain/context-graph/failures.md                # Deprecated patterns    â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   Updated via INNER LOOP (daily)                                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    LOGS (Daily Artifacts)                                 â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   logs/predictions/YYYY-MM-DD.json   # Daily prediction outputs           â”‚ â”‚
â”‚  â”‚   logs/evaluations/YYYY-MM-DD.json   # Daily evaluation results           â”‚ â”‚
â”‚  â”‚   logs/reflections/YYYY-MM-DD.md     # Daily learnings & hypotheses       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                    â”‚                    â”‚                    â”‚
          â–¼                    â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Snowflake     â”‚  â”‚   Glean MCP     â”‚  â”‚   Web Search    â”‚  â”‚   Git           â”‚
â”‚   (32 Tables)   â”‚  â”‚   (Internal KB) â”‚  â”‚   (External)    â”‚  â”‚   (Versioning)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 Knowledge Types

| Aspect | CLAUDE.md (Instructions) | Skills (Procedural) | Context Graph (Semantic) |
|--------|--------------------------|---------------------|--------------------------|
| **Type** | "What to do" | "How to do it" | "What is true" |
| **Content** | High-level directives, constraints, goals | Steps, queries, algorithms | Patterns, facts, relationships |
| **Examples** | "Always use point-in-time queries" | "How to calculate F1 score" | "Supplier X delays on Fridays" |
| **Loading** | **Always loaded** (auto-read) | **On-demand** (invoked) | **On-demand** (retrieved) |
| **Learning Loop** | N/A (manual) | **Outer (periodic)** | **Inner (daily)** |
| **Update Trigger** | Rarely (fundamental changes) | When process improves | When new patterns discovered |
| **Persistence** | `CLAUDE.md` in key directories | `.claude/skills/*.md` | `brain/context-graph/*.md` |
| **Scope** | Project-wide principles | Task-specific procedures | Instance-specific facts |

**Analogy**:
- **CLAUDE.md** = "Drive safely, follow traffic rules" (principlesâ€”always in mind)
- **Skills** = "How to parallel park" (procedural memoryâ€”recalled when needed)
- **Context Graph** = "This road floods when it rains" (semantic memoryâ€”retrieved by context)

**Loading Hierarchy**:
```
ALWAYS LOADED (auto-read on entry):
  â””â”€â”€ CLAUDE.md files in current + parent directories

LOADED ON DEMAND (invoked explicitly):
  â””â”€â”€ Skills via trigger phrases ("evaluate predictions", "predict OOS")

RETRIEVED BY CONTEXT (during prediction):
  â””â”€â”€ Context graph patterns matching current SKU/POD/signals
```

### 3.4 Skills (Procedural Knowledge)

Four skills form the daily cycle. Located at `.claude/skills/`. Implementation details are discovered through iterationâ€”these are guidelines, not prescriptions.

#### Skill: `evaluate`

Compare yesterday's predictions against actual OOS outcomes.

| Aspect | Detail |
|--------|--------|
| **Trigger** | "evaluate predictions", "check F1" |
| **Inputs** | `logs/predictions/{yesterday}.json`, Snowflake availability data |
| **Outputs** | `logs/evaluations/{yesterday}.json` |
| **Ground Truth** | Availability < X% = OOS (threshold TBD) |

**Process**: Load predictions â†’ Query actuals from Snowflake â†’ Calculate precision/recall/F1 â†’ Track which patterns triggered each prediction â†’ Write evaluation with per-prediction error details.

**Failure Modes**: Missing prediction file (skip day, log gap), Snowflake timeout (retry 3x, then skip).

#### Skill: `reflect`

Learn from prediction errors and update the context graph.

| Aspect | Detail |
|--------|--------|
| **Trigger** | "reflect on errors", "update patterns" |
| **Inputs** | `logs/evaluations/{yesterday}.json`, Glean (past RCAs/incidents) |
| **Outputs** | `brain/context-graph/patterns/`, `logs/reflections/{today}.md` |
| **Thresholds** | Add pattern: 10+ observations; Deprecate: F1 <0.50 |

**Process**: Analyze errors from evaluation â†’ Cluster by root cause â†’ Search Glean for past RCAs â†’ Extract patterns (only after 10+ observations) â†’ Deprecate failing patterns to `failures.md` â†’ Update `signals.md` with revised importance â†’ Write daily learnings to `reflections/`.

**Failure Modes**: No errors to analyze (skip reflection, note in log), Glean timeout (proceed without historical context).

#### Skill: `predict`

Forecast tomorrow's OOS with reasoning.

| Aspect | Detail |
|--------|--------|
| **Trigger** | "predict OOS", "forecast availability" |
| **Inputs** | `brain/context-graph/patterns/`, `signals.md`, Snowflake (inventory/PO/supplier), Web (events) |
| **Outputs** | `logs/predictions/{tomorrow}.json` |
| **Scope** | Bangalore, Bradman FMCG Tier A, Top WH by volume |

**Process**: Read `signals.md` for importance ranking â†’ Retrieve relevant patterns from context graph â†’ Query Snowflake for current inventory, PO status, supplier metrics â†’ Check external events (IPL, weather, festivals) via web search â†’ Check Glean for ongoing incidents â†’ Generate predictions with matched patterns and reasoning.

**Failure Modes**: Snowflake partial failure (predict with available data, flag confidence), Web search timeout (proceed without external events).

#### Skill: `context-graph-management`

Guidelines for storing and retrieving patterns.

**Pattern Generalization Principle**: Patterns are learned at **higher granularity** than predictions for signal density:

```
PATTERN LEVEL (learned):          PREDICTION LEVEL (applied):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Category Ã— Signal                 SKU Ã— WH
"Dairy + DOH<1 â†’ 80% OOS"   â”€â”€â”€â–º  "SKU 12345 at WH 7 â†’ OOS"
                                   (SKU 12345 is dairy, DOH=0.5)

Supplier Ã— Temporal               SKU Ã— WH
"Supplier X + Friday â†’ delay" â”€â”€â–º "SKU 67890 at WH 3 â†’ OOS"
                                   (SKU 67890 from Supplier X)
```

This allows patterns to generalize across SKUs while predictions remain actionable at SKU Ã— WH level.

| Aspect | Detail |
|--------|--------|
| **Core Principle** | Structure IS the indexâ€”organize by retrieval dimension |
| **Dimensions** | `by-category/`, `by-supplier/`, `by-temporal/`, `by-signal/`, `external/` |
| **Format** | Consistent markdown headers for grep-ability |
| **Duplication** | OK if pattern spans multiple dimensions |

**Storage Rules**:
- One pattern per H2 header (`## Pattern: {id}`)
- Always include: triggers, action, F1, observation count
- Cross-reference related patterns via links

**Retrieval**: Use Glob for dimension, Grep for specific conditions.

### 3.5 Learning Loops

Two distinct feedback loops drive system improvement:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       INNER LOOP (Daily)                            â”‚
â”‚                    Context Graph Evolution                          â”‚
â”‚                                                                     â”‚
â”‚   Evaluate â†’ Reflect â†’ Predict â†’ [24 hours] â†’ Evaluate â†’ ...        â”‚
â”‚                                                                     â”‚
â”‚   Updates: patterns/, signals.md, failures.md, reflections/         â”‚
â”‚   Scope: "What is true" - semantic knowledge about the world        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â”‚ reflections accumulate
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     OUTER LOOP (Periodic)                           â”‚
â”‚                       Skill Evolution                               â”‚
â”‚                                                                     â”‚
â”‚   Review reflections â†’ Identify process gaps â†’ Update skills        â”‚
â”‚                                                                     â”‚
â”‚   Updates: .claude/skills/*.md, scripts/                            â”‚
â”‚   Scope: "How to do it better" - procedural knowledge improvement   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Inner Loop: Context Graph Updates

The daily cycle (evaluate â†’ reflect â†’ predict) updates semantic knowledge:

| Artifact | What Gets Updated | Trigger |
|----------|-------------------|---------|
| `patterns/` | New patterns added when 10+ observations confirm | Daily, during reflect |
| `signals.md` | Signal importance rankings revised | Daily, based on error analysis |
| `failures.md` | Patterns deprecated when F1 < 0.50 | Daily, during reflect |
| `reflections/` | Daily learnings, error clusters, hypotheses | Daily, end of reflect |

**Stability**: Context graph changes daily, but individual patterns require evidence (10+ observations) before being added.

#### Outer Loop: Skill Evolution

Skills are procedural knowledgeâ€”they change less frequently and require more validation:

| Trigger | Example | Action |
|---------|---------|--------|
| **Weekly review** | End of Week 1, end of Week 2 | Human + Claude review `reflections/`, identify process gaps |
| **Error threshold** | Same error type 5+ times | Claude proposes skill improvement, human approves |
| **Performance plateau** | F1 stuck below target | Analyze which skill phase is bottleneck |
| **Human-initiated** | "Improve supplier delay detection" | Direct instruction to update specific skill |

**Process:**
1. **Aggregate** - Read all `logs/reflections/*.md` from period
2. **Identify gaps** - Find recurring errors about process, not just missing patterns
3. **Propose changes** - Draft updates to SKILL.md or scripts/
4. **Validate** - Run simulation subset with new skill
5. **Commit** - If performance improves, commit skill changes

**Examples of skill improvements:**
- "Evaluate uses wrong OOS threshold (50% vs 30%)" â†’ Update `evaluate/SKILL.md`
- "Predict should check PO status before inventory levels" â†’ Update `predict/SKILL.md`
- "Reflect adds patterns too aggressively (5 obs instead of 10)" â†’ Update `reflect/SKILL.md`
- "Supplier metric query misses key columns" â†’ Update `scripts/fetch_supplier.sql`

**Why separate loops?**
- **Stability**: Skills shouldn't thrash based on one bad day
- **Evidence**: Process changes need multiple days of data to validate
- **Testability**: Skill changes can be A/B tested in simulation
- **Human oversight**: Procedural changes are higher-risk, warrant review

#### Rollback & Recovery

| Trigger | Action |
|---------|--------|
| F1 drops >15% after pattern update | `git revert` to previous context graph |
| Pattern F1 <0.40 for 3 consecutive days | Auto-deprecate to `failures.md` |
| Skill change causes regression | Revert skill, re-run simulation subset |
| Snowflake outage during evaluation | Skip day, note gap in `reflections/` |

**Recovery principle**: Context graph is version-controlled. Every state is recoverable via git history.

### 3.6 Tools Available to Agent

| Tool | Purpose | Access Method |
|------|---------|---------------|
| **Snowflake** | Query any of 32 tables | `snowsql` CLI via Bash |
| **Glean Search** | Search Confluence, Jira, Slack, Docs | `mcp__glean_default__search` |
| **Glean Chat** | AI-powered synthesis across sources | `mcp__glean_default__chat` |
| **Glean Read** | Read full document by URL | `mcp__glean_default__read_document` |
| **Glean Code** | Search internal code repos | `mcp__glean_default__code_search` |
| **Web Search** | External events (IPL, festivals, weather) | `WebSearch` tool |
| **Web Fetch** | Fetch specific URLs | `WebFetch` tool |
| **Git** | Version control for context graph | `git` via Bash |
| **Python** | Statistical analysis, ML models | `python` via Bash |
| **File I/O** | Read/Write/Edit files | Read, Write, Edit tools |

**Skill Reference**: `/knowledge-work:glean-connector` for enterprise knowledge queries.

### 3.7 Directory Structure

**Root**: `/Users/sidhant.panda/workspaces/root-workspace/swiggy-brain/scm/pocs/availability-prediction/`

```
availability-prediction/
â”œâ”€â”€ .claude/
â”‚   â””â”€â”€ skills/
â”‚       â”œâ”€â”€ evaluate/
â”‚       â”‚   â”œâ”€â”€ SKILL.md
â”‚       â”‚   â””â”€â”€ scripts/
â”‚       â”‚       â””â”€â”€ calculate_metrics.py
â”‚       â”œâ”€â”€ reflect/
â”‚       â”‚   â”œâ”€â”€ SKILL.md
â”‚       â”‚   â””â”€â”€ scripts/
â”‚       â”‚       â””â”€â”€ cluster_errors.py
â”‚       â”œâ”€â”€ predict/
â”‚       â”‚   â”œâ”€â”€ SKILL.md
â”‚       â”‚   â””â”€â”€ scripts/
â”‚       â”‚       â”œâ”€â”€ fetch_inventory.sql
â”‚       â”‚       â””â”€â”€ apply_patterns.py
â”‚       â””â”€â”€ context-graph-management/
â”‚           â””â”€â”€ SKILL.md          â† Storage & retrieval philosophy
â”‚
â”œâ”€â”€ brain/
â”‚   â”œâ”€â”€ CLAUDE.md                 â† Auto-read by Claude Code
â”‚   â””â”€â”€ context-graph/
â”‚       â”œâ”€â”€ patterns/
â”‚       â”‚   â”œâ”€â”€ by-category/      â† dairy.md, beverages.md, staples.md
â”‚       â”‚   â”œâ”€â”€ by-supplier/      â† chronic-delay-suppliers.md
â”‚       â”‚   â”œâ”€â”€ by-temporal/      â† friday.md, weekend.md, month-end.md
â”‚       â”‚   â”œâ”€â”€ by-signal/        â† low-doh.md, low-fill-rate.md
â”‚       â”‚   â””â”€â”€ external/         â† ipl.md, weather.md
â”‚       â”œâ”€â”€ signals.md            â† Signal importance rankings
â”‚       â””â”€â”€ failures.md           â† Deprecated patterns & lessons
â”‚
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ predictions/
â”‚   â”‚   â””â”€â”€ YYYY-MM-DD.json       â† Daily prediction outputs
â”‚   â”œâ”€â”€ evaluations/
â”‚   â”‚   â””â”€â”€ YYYY-MM-DD.json       â† Daily evaluation metrics
â”‚   â””â”€â”€ reflections/
â”‚       â””â”€â”€ YYYY-MM-DD.md         â† Daily learnings & hypotheses
â”‚
â””â”€â”€ CLAUDE.md
```

### 3.8 Context Graph & Logs Format

#### Context Graph (Flexibleâ€”Agent Discovers)

**Patterns** (`brain/context-graph/patterns/by-{dimension}/*.md`): See [context-graph-management skill](#skill-context-graph-management) for format and storage rules.

**Signals** (`brain/context-graph/signals.md`): Ranked list of signals by predictive power. Updated by reflect skill.

**Failures** (`brain/context-graph/failures.md`): Deprecated patterns with original triggers, why it failed, and lesson learned.

#### Predictions Schema (Fixed)

`logs/predictions/YYYY-MM-DD.json`:
```json
{
  "date": "YYYY-MM-DD",
  "generated_at": "ISO timestamp",
  "predictions": [
    {
      "sku_id": "string",
      "wh_id": "string",
      "prediction": "OOS | IN_STOCK",
      "confidence": 0.0-1.0,
      "patterns_matched": ["pattern_id", ...],
      "signals": { "signal_name": value, ... },
      "reasoning": "string"
    }
  ]
}
```

#### Evaluations Schema (Fixed)

`logs/evaluations/YYYY-MM-DD.json`:
```json
{
  "date": "YYYY-MM-DD",
  "metrics": { "precision": 0.XX, "recall": 0.XX, "f1": 0.XX },
  "confusion": { "tp": N, "fp": N, "tn": N, "fn": N },
  "errors": [
    {
      "sku_id": "string",
      "wh_id": "string",
      "predicted": "OOS | IN_STOCK",
      "actual": "OOS | IN_STOCK",
      "patterns_used": ["pattern_id", ...],
      "signals_at_prediction": { ... }
    }
  ],
  "pattern_performance": {
    "pattern_id": { "tp": N, "fp": N, "fn": N, "f1": 0.XX }
  }
}
```

#### Reflections (Flexibleâ€”Agent Discovers)

`logs/reflections/YYYY-MM-DD.md`: Daily learningsâ€”error clusters, pattern updates made, hypotheses for tomorrow. Format evolves as agent learns what's useful to capture.

---

## 4. POC Scope & Constraints

### 4.1 Scope

| Dimension | Scope | Rationale |
|-----------|-------|-----------|
| **City** | Bangalore only | Largest volume, best data quality |
| **Category** | FMCG only | Excludes FnV (perishable complexity), Electronics, etc. |
| **SKU tier** | Bradman FMCG Tier A | Top 20% of Bradman FMCG by Bradman score (~1,200 SKUs) |
| **Warehouse** | Top 1 by volume | Single highest-volume WH serving Bangalore. WH-led issues are 3Ã— more common. |
| **Velocity** | â‰¥1 unit sold/day at WH | Ensures learning signal exists |
| **Active** | SKU enabled at WH | Skip de-listed or seasonal |
| **Prediction** | Binary OOS (availability < X%) | Simpler than regression, threshold TBD |
| **Horizon** | Tomorrow (T+1) | 24hr feedback loop |

**What is Bradman?** "Project Bradman 99.90" is a strategic supply chain initiative targeting **99.90% availability** for high-priority SKUs (named after Don Bradman's 99.94 batting average). Bradman SKUs are selected via weighted scoring (20% each): GSV, Units Sold, Impressions, Search HC Impressions, and I2C. Scope: ~19K+ SKUs across Bangalore.

**POC Tiering** (subset of Bradman FMCG):

| Tier | Criteria | Est. SKUs | POC Scope |
|------|----------|-----------|-----------|
| **Tier A** | Top 20% by Bradman score | ~1,200 | âœ… Phase 1 (WHÃ—SKU) |
| **Tier B** | Next 30% by Bradman score | ~1,800 | Phase 2 |
| **Tier C** | Remaining 50% | ~3,000 | Phase 3 |

**Estimated daily scope**: ~1,200 SKUs Ã— 1 WH Ã— velocity filter â†’ **~1,200 predictions/day**

> **Phase 2 Expansion**: After validating WHÃ—SKU predictions, can expand to PODÃ—SKU level (~1,200 SKUs Ã— 20 PODs â†’ ~2,000-4,000 predictions/day)

### 4.2 Success Metrics

| Metric | Baseline | Target | Measurement |
|--------|----------|--------|-------------|
| **Self-Improvement (PRIMARY)** | Day 1 F1 | Positive slope | Final week F1 > First week F1 |
| **Prediction F1 (SECONDARY)** | 0.50 (random) | >0.70 | Average F1 over final week of simulation |
| **Pattern Discovery** | 0 (cold start) | 10+ validated | Patterns with F1 >0.70 |
| **Context Efficiency** | Day 1 tokens | -20% | Token usage reduction over 30 days |

> **Primary Metric: Self-Improvement Slope** â€” Validates the core hypothesis that prediction pressure drives learning. Success = positive F1 slope over simulation period.

> **Secondary Metric: F1** â€” Balances precision (avoid false alarms) and recall (catch stockouts). See [Section 3.1.2](#312-ground-truth--evaluation) for calculation details. Patterns validated at F1 >0.70, deprecated at <0.50.

#### Self-Improvement Slope (Key Exit Criterion)

We measure **improvement rate** to validate that the system learns over time:

```
Improvement % = (F1_final_week - F1_first_week) / F1_first_week Ã— 100

Example: F1 improves from 0.55 (week 1) to 0.72 (week 4) â†’ 31% improvement
```

**Visualization**: Plot daily F1 scores and fit a trend line. Success = positive slope.

```
F1
 â”‚
0.8â”¤                                    â•­â”€â”€â—
   â”‚                              â•­â”€â”€â”€â”€â—
0.7â”¤                        â•­â”€â”€â”€â”€â—
   â”‚                  â•­â”€â”€â”€â”€â—
0.6â”¤            â•­â”€â”€â”€â”€â—
   â”‚      â•­â”€â”€â”€â”€â—
0.5â”¤ â—â”€â”€â”€â—
   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Day
     1    5    10   15   20   25   30
```

**Threshold (X): TBD** â€” Will determine target improvement % after analyzing Week 1 baseline. Considerations:
- Minimum viable: â‰¥10% improvement (system is learning)
- Strong signal: â‰¥25% improvement (clear value demonstrated)
- If flat or negative slope: hypothesis invalidated, pivot needed

### 4.3 External Events 

External events can be looked up by the agent using the web search tool.

| Event Type | Current Gap | POC Approach |
|------------|-------------|--------------|
| IPL Matches | 20.1% MAPE vs 17.5% | Web Search for schedule |
| Festivals | Timing variability | Web Search for dates |
| Weather | Only rain flag | Web Search for forecasts |
| City Events | Not captured | Web Search for local events |

### 4.4 Anti-Cheat Requirements

During historical simulation, all queries MUST be point-in-time filtered:
```sql
WHERE event_date <= '{simulation_date}'
AND updated_at <= '{simulation_date} 23:59:59'
```

No future data leakage. Claude Code enforces this constraint.

---

## 5. Execution Plan

This POC is built **by Claude Code, with human supervision**. Claude Code is both the builder AND the runtime system. Human provides direction; Claude implements, tests on historical data, and iterates. No waiting for "tomorrow"â€”historical simulation provides instant feedback.

**Build Loop:**
```
HUMAN: High-level instruction
    â”‚
    â–¼
CLAUDE CODE: Implement
    â”‚
    â–¼
CLAUDE CODE: Test on historical data (instant feedback)
    â”‚
    â–¼
PASS? â”€â”€â”€ No â”€â”€â†’ CLAUDE CODE: Analyze error, fix, retry
    â”‚
   Yes
    â–¼
CLAUDE CODE: Commit to git
    â”‚
    â–¼
HUMAN: Review, approve, next instruction
```

### Calendar & Working Days

```
January 2026
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ Mon â”‚ Tue â”‚ Wed â”‚ Thu â”‚ Fri â”‚ Sat â”‚ Sun â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚ 12  â”‚ 13  â”‚ 14  â”‚ 15  â”‚ 16  â”‚ 17  â”‚ 18  â”‚  â† WEEK 1: BUILD
â”‚ D1  â”‚ D2  â”‚ D3  â”‚ HOL â”‚ D4  â”‚ off â”‚ off â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚ 19  â”‚ 20  â”‚ 21  â”‚ 22  â”‚ 23  â”‚ 24  â”‚ 25  â”‚  â† WEEK 2: SIMULATION
â”‚ D5  â”‚ D6  â”‚ D7  â”‚ D8  â”‚ D9  â”‚ off â”‚ off â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚ 26  â”‚ 27  â”‚ 28  â”‚ 29  â”‚ 30  â”‚ 31  â”‚     â”‚  â† WEEK 3: LIVE + DEMO
â”‚ HOL â”‚ D10 â”‚ D11 â”‚ D12 â”‚ D13 â”‚     â”‚     â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

D# = Working Day    HOL = Holiday    off = Weekend
Holidays: Jan 15 (Thu) Pongal, Jan 26 (Mon) Republic Day
```

### Week 1: BUILD (Jan 12-16)

**Goal**: All skills built, full cycle working, ready for simulation.

> **4 working days** (Mon-Wed Jan 12-14, Fri Jan 16). Jan 15 Thu is Pongal holiday.

| Day | Date | Deliverable |
|-----|------|-------------|
| **1-2** | Mon-Tue, Jan 12-13 | Directory structure, Snowflake CLI, `evaluate` skill, baseline F1 |
| **3-4** | Wed+Fri, Jan 14+16 | `predict` + `reflect` skills, full cycle working, warm-up (Dec 20-22) |

**Week 1 Exit Criteria:**
- [ ] All skills complete (evaluate, predict, reflect, context-graph-management)
- [ ] Full cycle working (predict â†’ evaluate â†’ reflect)
- [ ] Test run on Dec 20 data successful
- [ ] Ready for simulation

### Week 2: SIMULATION (Jan 19-23)

**Goal**: Run complete 30-day historical simulation. Context graph warm with patterns, ready for live.

> **5 working days** (Mon-Fri). Run ~6 simulated days per real day.

| Day | Date | Deliverable |
|-----|------|-------------|
| **5** | Mon, Jan 19 | Simulation Days 1-6 (Dec 19-24, Christmas Eve) |
| **6** | Tue, Jan 20 | Simulation Days 7-12 (Dec 25-30, Christmas) |
| **7** | Wed, Jan 21 | Simulation Days 13-18 (Dec 31 - Jan 5, New Year) |
| **8** | Thu, Jan 22 | Simulation Days 19-24 (Jan 6-11, post-holiday) |
| **9** | Fri, Jan 23 | Simulation Days 25-30 (Jan 12-18, Pongal) + Human Review |

**Week 2 Exit Criteria (End of Day 9):**
- [ ] 30-day simulation complete (Dec 19 â†’ Jan 18)
- [ ] **PRIMARY: Positive F1 slope** (Final week F1 > First week F1)
- [ ] **SECONDARY: F1 > 0.70** on final week average
- [ ] 10+ validated patterns discovered (F1 > 0.70)
- [ ] Context graph committed to main
- [ ] Human review sign-off: "Context graph approved for live"

### Week 3: LIVE + DEMO (Jan 27-30)

**Goal**: Live predictions on real data, stakeholder demo, scaling plan.

> **4 working days** (Tue-Fri). Jan 26 Mon is Republic Day holiday.

| Day | Date | Deliverable |
|-----|------|-------------|
| **10** | Tue, Jan 27 | First live prediction (predict Jan 28 using Jan 26 EOD data) |
| **11** | Wed, Jan 28 | First live evaluation + predict Jan 29 |
| **12** | Thu, Jan 29 | Documentation, external events analysis, demo prep |
| **13** | Fri, Jan 30 | Stakeholder demo delivered, scaling plan documented |

**POC Exit Criteria:**
- [ ] **PRIMARY: Self-improvement validated** (positive F1 slope in simulation)
- [ ] Live F1 > 0.75
- [ ] 3+ days of live predictions
- [ ] External events validated
- [ ] Stakeholder demo delivered
- [ ] Scaling plan documented

### Risks & Mitigations

| Risk | Mitigation |
|------|------------|
| Data quality issues | Start with Bradman SKUs; validate freshness |
| Sparse signal at SKU level | Aggregate to PODÃ—Category if needed |
| Pattern overfitting | Min 10 observations before adding pattern |
| Context graph bloat | Aggressive compression; decay old patterns |
| Simulation vs reality gap | Run parallel live predictions after validation |

---

## Appendix A: Data Tables

### Core Inventory & Availability

| Signal | Table | POC Relevance |
|--------|-------|---------------|
| Inventory State | `dash-scm-inventory-availability` | âœ… Core â€” DynamoDB (~231M items), real-time sellable qty. Primary signal for current stock levels. |
| Inventory Detail | `dash-scm-inventory-location` | âœ… Signal â€” batch/location/expiry tracking via ILS. Use for DOH calculation and FEFO analysis. |
| Inventory Planning | `dash-scm-inventory-planning` | ğŸ“‹ Reference â€” transaction planning, idempotency. Less relevant for prediction. |
| Control Room Rules | `scm-control-room-rules` | âœ… Signal â€” ~404K rules for OOS overrides, holiday slots. Critical for Branch 6 (config-led) detection. |
| Availability RCA | `analytics.public.sku_wise_availability_rca_with_reasons_v7` | âœ… Core â€” **Ground truth for evaluation**. Waterfall attribution to 28 reason codes. Use for reflect skill. |
| Weighted Availability | `analytics.public.weighted_availability_daily_update` | âœ… Core â€” **Impression-weighted availability** for OOS definition. Primary metric for prediction target. |
| Reason Mapping | `analytics.public.final_reason_mapping_avail_rca` | âœ… Core â€” Maps `final_reason` â†’ `bin`, `ai_owner`, `notes`, `rnk`. Critical for RCA aggregation. |
| RCA Aggregates | `analytics.public.im_availability_rca_overall_part_1*` | âœ… Signal â€” Pre-aggregated RCA by city, category, band. Quick dashboards for pattern validation. |

### Forecasting & Orders

| Signal | Table | POC Relevance |
|--------|-------|---------------|
| TFT Forecast | `data_science.ds_storefront.im_pod_hr_demand_forecasting` | âœ… Signal â€” Pod-hour demand forecast (MAPE ~18.6%). Compare forecast vs actual for Branch 1 (forecasting-led). |
| Historical Orders | `analytics.public.im_parent_order_fact` | âœ… Signal â€” demand velocity, order patterns. Calculate run rates for DOH signals. |
| Pod Availability | `analytics.public.pr_hr_level_avl` | âœ… Core â€” hourly availability by POD. Aggregates to daily availability for ground truth. |
| Demand Timeseries | `data_science.im_b2b_demand_forecast_fnv_timeseries_data` | âœ… Signal â€” Demand attribution pipeline output. Joins sales, search, availability at SKU level. |
| Store Master | `prod.swiggykms.stores` | ğŸ“‹ Reference â€” POD metadata (tier, location, last-mile threshold). |

### Procurement & PO

| Signal | Table | POC Relevance |
|--------|-------|---------------|
| PO Status | `scm-procurement-po` | âœ… Signal â€” PO lifecycle (DRAFTâ†’CONFIRMEDâ†’CLOSED). Detect stuck/expired POs for Branch 2 (PO-led). |
| PO Details | `scm-procurement-po-details` | âœ… Signal â€” line-item quantities, fill rates. Key for measuring PO execution. |
| Booking Slots | `analytics_adhoc.booking_portal_bookings` | âœ… Signal â€” warehouse appointment scheduling. Delays here â†’ Branch 4 (warehouse ops-led). |
| PO Automation | `analytics_adhoc.po_automation_metrics` | ğŸ“‹ Reference â€” ~45% automation coverage. Context for manual vs auto PO patterns. |

### Supplier Performance

| Signal | Table | POC Relevance |
|--------|-------|---------------|
| Supplier PO Metrics | `analytics_prod.im_vendor_portal_po_module` | âœ… Signal â€” OTIF, UFR, LFR, lead times. Primary data for Branch 3 (supply-led). |
| Supplier Scoring | `supplier_performance_metrics` (ES) | âœ… Signal â€” real-time composite scores (0.4Ã—OTIF + 0.3Ã—UFR + 0.2Ã—LTA + 0.1Ã—Quality). |
| Vendor Inventory | `analytics_prod.im_vendor_portal_inventory_module` | âœ… Signal â€” upstream stock visibility. Early warning for supply constraints. |
| Supplier Master | `dash_scm_supplier_master` | ğŸ“‹ Reference â€” supplier metadata, contact, tiers. |

### POD Operations

| Signal | Table | POC Relevance |
|--------|-------|---------------|
| Rack Management | `dash-scm-rack-management-v2` | ğŸ“‹ Reference â€” POD capacity, bin locations. Context for Branch 5 (dark store-led). |
| Contract/Tiering | `contract-master` | âœ… Signal â€” SKU tiering, Bradman membership, assortment. **Critical for POC scope filtering.** |

### Warehouse CDC (Vinculum)

| Signal | Table | POC Relevance |
|--------|-------|---------------|
| GRN/Inbound | `vinculum.swiggy_gamma.inbound` / `inbounddetail` | âœ… Signal â€” GRN timestamps, received qty vs PO qty. Detect inwarding delays for Branch 4. |
| PO Lifecycle | `vinculum.swiggy_gamma.po` / `podetail` | âœ… Signal â€” PO status in WMS. Cross-check with MIM for sync issues. |
| Inventory Balance | `vinculum.swiggy_gamma.invbal` | âœ… Signal â€” warehouse SOH (stock on hand). Source for WH-level DOH calculation. |
| Dispatch | `vinculum.swiggy_gamma.dispatch` / `delmanifest` | âœ… Signal â€” dispatch to POD timing. Detect movement delays for Branch 4. |

**Note**: Vinculum CDC tables sync via AWS DMS with 15-120 min lag. Use for historical patterns, not real-time signals.

---

## Appendix B: DS Pipelines Reference

| Pipeline | Purpose | Output Table | POC Relevance |
|----------|---------|--------------|---------------|
| **TFT Demand Forecasting** | 10-stage pipeline predicting pod-hour demand using Temporal Fusion Transformer | `data_science.ds_storefront.im_pod_hr_demand_forecasting` | âœ… Signal â€” Compare forecast vs actual sales. Gap indicates Branch 1 (forecasting-led) issues. MAPE ~18.6% normal, 20.1% during IPL. |
| **Demand Attribution** | Traces sessions â†’ search â†’ impressions â†’ orders â†’ SKU sales. 9 intermediate tables. | `data_science.im_b2b_demand_forecast_fnv_timeseries_data` | âœ… Signal â€” Joins sales, search volume, availability at SKU level. Use for demand velocity signals. |
| **Weighted Availability** | Calculates impression-weighted availability per SKUÃ—PODÃ—day | `analytics.public.weighted_availability_daily_update` | âœ… Core â€” **Primary metric for OOS definition**. Weights by customer sessions, not clock time. |
| **Availability Attribution** | Waterfall logic attributing OOS to 7 deterministic branches | `analytics.public.sku_wise_availability_rca_with_reasons_v7` | âœ… Core â€” **Ground truth for RCA**. Use in reflect skill to understand why prediction was wrong. |
| **FnV Movement Planning** | 3-stage PuLP optimization for perishable inventory movement | `movement-planning` tables | âŒ Out of scope â€” FnV excluded from POC |

**Key Parameters**:
- TFT: Lookback 7-14 days, Prediction 1-14 days, Quantiles [0.4, 0.5, 0.6, 0.7, 0.8]
- TFT MAPE: 18.6% (normal), 20.1% (IPL) â† opportunity for external event signals
- Low-volume PODs (OPD<500) have **4.6x worse forecast accuracy** (22% vs 4.8% WAPE)

---

## Appendix C: Availability Reason Codes

The waterfall assigns each SKUÃ—POD to exactly one `final_reason`. Reasons are prioritized in order (first match wins). Understanding these codes is critical for the POC's reflect skill to learn meaningful patterns.

### RCA Taxonomy Overview

![Store Availability RCA Taxonomy](./images/store-availability-rca-taxonomy.png)

**Figure: Store Availability Issue Tree** â€” Two main branches: WH-led (~12.8% of miss) and POD-led (~4.7% of miss).

<details>
<summary>Taxonomy Text Reference (click to expand)</summary>

```
STORE AVAILABILITY
â”‚
â”œâ”€ A. WH-led Availability Miss (~12.8%)
â”‚   â”‚
â”‚   â”œâ”€ A1. Supplier & Inbound Constraints
â”‚   â”‚   â”œâ”€ A1.1 Vendor Fill Rate & LT Supply Issues
â”‚   â”‚   â””â”€ A1.2 MOQ / MOV / Case Size / Contract / OTIF
â”‚   â”‚
â”‚   â”œâ”€ A2. WH-side Planning & Forecasting
â”‚   â”‚   â”œâ”€ A2.1 Under-biased Forecasts (even with good fill rate)
â”‚   â”‚   â””â”€ A2.2 Demand Shocks (price / visibility / events / tiering)
â”‚   â”‚
â”‚   â”œâ”€ A3. Warehouse Throughput & Capacity
â”‚   â”‚   â”œâ”€ A3.1 Low Outbound Fill Rate & Backlog
â”‚   â”‚   â”œâ”€ A3.2 WH Capacity / Space Constraints
â”‚   â”‚   â”œâ”€ A3.3 Putaway / Backlog Delays ('physically present but unavailable')
â”‚   â”‚   â””â”€ A3.4 Productivity-driven De-prioritisation of bulky / tail SKUs
â”‚   â”‚
â”‚   â””â”€ A4. Inventory Hygiene & Systems (WH)
â”‚       â”œâ”€ A4.1 ERP Disabled / Movement Blocking
â”‚       â”œâ”€ A4.2 Phantom Inventory & Quality / Expiry Holds
â”‚       â””â”€ A4.3 Reason / Ownership Gaps ('Others / Unallocated')
â”‚
â””â”€ B. POD-led Availability Miss (~4.7%)
    â”‚
    â”œâ”€ B1. POD Ops Throughput & Capacity
    â”‚   â”œâ”€ B1.1 POD Missed Qty & OPD > Inbound
    â”‚   â”œâ”€ B1.2 Inwarding Delays vs Morning Peak
    â”‚   â”œâ”€ B1.3 POD Space Constraints (incl. freezer / chiller)
    â”‚   â””â”€ B1.4 Pod Closure / Unserviceability & Spillover
    â”‚
    â”œâ”€ B2. POD-level Planning & Demand Dynamics
    â”‚   â”œâ”€ B2.1 Forecast Error at POD Granularity
    â”‚   â””â”€ B2.2 Cannibalisation / Substitution Misses
    â”‚
    â”œâ”€ B3. Replenishment Logic & Movement Design
    â”‚   â”œâ”€ B3.1 Null / Mis-estimated PODÃ—SKU Run Rates
    â”‚   â”œâ”€ B3.2 Finite Capacity Rounding (low-RR SKUs)
    â”‚   â”œâ”€ B3.3 Movement Setting Design Issues (caps, min/max)
    â”‚   â””â”€ B3.4 ERP / Movement Blocks at POD
    â”‚
    â””â”€ B4. Inventory Hygiene & Freshness (POD)
        â”œâ”€ B4.1 FIFO Misses & Fresh Wastage
        â””â”€ B4.2 Quality / Expiry Holds
```

</details>

### Mapping: Taxonomy â†’ Waterfall Codes

| Taxonomy Code | Description | Waterfall Code(s) |
|---------------|-------------|-------------------|
| **A1** | Supplier & Inbound | `oos_8`, `oos_9` |
| **A2** | WH Planning/Forecasting | `oos_10` |
| **A3** | WH Throughput/Capacity | `instock_9`, `instock_10`, `instock_12`, `instock_15` |
| **A4** | WH Inventory Hygiene | `oos_2`, `oos_3`, `oos_4`, `instock_17` |
| **B1** | POD Ops/Capacity | `instock_8`, `instock_11`, `instock_14` |
| **B2** | POD Planning/Demand | `instock_13` |
| **B3** | Movement Design | `oos_6`, `oos_7`, `instock_6`, `instock_7`, `instock_16` |
| **B4** | POD Inventory Hygiene | `instock_0-5` (config codes) |

### When Warehouse Stock = OOS (upstream supply problem)

These codes indicate the warehouse itself doesn't have stock. The problem is "upstream" of POD operations.

| Code | Reason | What It Means | POC Relevance |
|------|--------|---------------|---------------|
| `oos_0` | `pod_inactive` | POD is disabled in system | âŒ Skip â€” not a prediction target (POD not serving) |
| `oos_1` | `disabled_pod` | Movement to this POD is blocked | âŒ Skip â€” config issue, not predictable demand/supply gap |
| `oos_2` | `Not in ERP` | SKU missing from ERP master | âŒ Skip â€” data hygiene issue, not inventory problem |
| `oos_3` | `temp_disable` | SKU temporarily disabled (quality hold, recall) | âš ï¸ Low â€” could predict if we track disable patterns |
| `oos_4` | `Order Blocking List` | SKU blocked from ordering | âŒ Skip â€” explicit business decision |
| `oos_5` | `Fresh_Items` | FnV/perishables special handling | âŒ Skip â€” FnV out of POC scope |
| `oos_6` | `movement_rr_not_generated` | No run-rate calculated â†’ no movement planned | âœ… Signal â€” indicates new SKU or planning gap |
| `oos_7` | `movement_rr_blocked` | Run-rate set to 0.001 (blocked) | âš ï¸ Low â€” explicit block, not predictable |
| `oos_8` | `Long Term Supply Issue` | Supplier hasn't delivered for extended period | âœ… Core â€” supplier reliability pattern, highly predictable |
| `oos_9` | `fillrate Issue` | Supplier delivered <80% of PO qty | âœ… Core â€” supplier fill rate pattern, key signal |
| `oos_10` | `Planning Ordering Issue` | No other reason â†’ default to planning gap | âœ… Core â€” catch-all for PO/planning failures |

### When Warehouse Stock = Instock (movement/POD problem)

These codes indicate warehouse has stock but POD doesn't. The problem is in movement or POD operations.

| Code | Reason | What It Means | POC Relevance |
|------|--------|---------------|---------------|
| `instock_0` | `pod_inactive` | POD is disabled | âŒ Skip â€” not serving |
| `instock_1` | `Not in ERP` | SKU missing from ERP at POD level | âŒ Skip â€” data issue |
| `instock_2` | `movement_blocked_list` | Movement explicitly blocked for this POD | âŒ Skip â€” config decision |
| `instock_3` | `temp diable` | Temporarily disabled at POD | âš ï¸ Low â€” could predict disable patterns |
| `instock_4` | `Order Blocking List` | Blocked from ordering at POD | âŒ Skip â€” explicit block |
| `instock_5` | `Fresh_Items` | FnV handling | âŒ Skip â€” out of scope |
| `instock_6` | `movement_rr_not_generated` | No run-rate at POD level | âœ… Signal â€” new SKU-POD mapping or gap |
| `instock_7` | `movement_rr_blocked` | Run-rate blocked at POD | âš ï¸ Low â€” explicit block |
| `instock_8` | `POD Cap Missed` | POD capacity full, couldn't receive | âœ… Core â€” capacity constraint pattern, predictable |
| `instock_9` | `WH Cap Missed` | Warehouse dispatch capacity exceeded | âœ… Core â€” warehouse throughput pattern |
| `instock_10` | `WH_Cap_Movement_Reduced` | Movement reduced due to WH constraints | âœ… Signal â€” partial fulfillment pattern |
| `instock_11` | `pod_Space Issue_cold` | Cold storage at POD full | âœ… Core â€” cold chain constraint, seasonal pattern |
| `instock_12` | `wh_ob_Fillrate Issue` | Warehouse outbound fill rate <80% | âœ… Core â€” warehouse execution pattern |
| `instock_13` | `Forecasting_error` | Actual sales >3Ã— forecast run-rate | âœ… Core â€” **demand spike pattern**, highly valuable |
| `instock_14` | `Putway_delay` | Inwarding to shelf delayed at POD | âœ… Signal â€” POD operations pattern |
| `instock_15` | `wh_putaway_delay` | Free DOH <3 days (stock stuck in staging) | âœ… Signal â€” warehouse operations pattern |
| `instock_16` | `Movement Design issue` | Movement plan design gap | âœ… Signal â€” planning algorithm gap |
| `instock_17` | `Others` | Catch-all for unexplained gaps | âš ï¸ Low â€” noisy, needs deeper investigation |

### POC Priority Summary

| Priority | Codes | Count | Pattern Type |
|----------|-------|-------|--------------|
| âœ… **Core** | oos_8, oos_9, oos_10, instock_8, instock_9, instock_11, instock_12, instock_13 | 8 | Supplier, capacity, forecasting â€” highest signal |
| âœ… **Signal** | oos_6, instock_6, instock_10, instock_14, instock_15, instock_16 | 6 | Operations patterns â€” secondary signals |
| âš ï¸ **Low** | oos_3, oos_7, instock_3, instock_7, instock_17 | 5 | Explicit blocks or noisy catch-alls |
| âŒ **Skip** | oos_0-2, oos_4-5, instock_0-2, instock_4-5 | 10 | Config/data issues, not predictable |

**Source**: `availability_attribution_waterfall.sql` â†’ `analytics.public.sku_wise_availability_rca_with_reasons_v7`

**Reason Mapping Table**: `analytics.public.final_reason_mapping_avail_rca`
```sql
SELECT final_reason, bin, ai_owner, notes, rnk
FROM analytics.public.final_reason_mapping_avail_rca
```

---

## Appendix D: Quick Reference

**Daily Commands:**
```bash
# Morning cycle (run in order)
cd /Users/sidhant.panda/workspaces/root-workspace/swiggy-brain/scm/pocs/availability-prediction
git pull origin main
# Then invoke: evaluate â†’ reflect â†’ predict
git add . && git commit -m "Daily cycle $(date +%Y-%m-%d)" && git push
```

**Debugging:**
```bash
# Check pattern performance
grep -r "F1:" brain/context-graph/patterns/

# View yesterday's errors
cat logs/evaluations/$(date -d "yesterday" +%Y-%m-%d).json | jq '.errors | length'

# Find deprecated patterns
cat brain/context-graph/failures.md

# Check F1 trend over last 7 days
for f in logs/evaluations/*.json; do echo -n "$f: "; jq '.metrics.f1' "$f"; done | tail -7
```

**Key Thresholds:**
| Parameter | Value |
|-----------|-------|
| OOS definition | Availability < X% (TBD) |
| Pattern minimum observations | 10 |
| Pattern deprecation threshold | F1 <0.50 |
| Auto-deprecate trigger | F1 <0.40 for 3 consecutive days |
| Outer loop trigger | Same error type 5+ times |
| Rollback trigger | F1 drops >15% |

---

## References

- [Prediction-Driven Context Graphs Concept](./prediction-driven-context-graphs.md)
- [Supply Chain Brain PRFAQ](./supply-chain-PRFAQ.md)
- [Swiggy Brain PRFAQ](https://docs.google.com/document/d/1de_Es5JyVlh2AJ6_ZSfXt_EuReaJYSo52dyPmaYJOzo)
- SCM Research: `scm-research/*.md`
